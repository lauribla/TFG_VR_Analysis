"""
VR USER EVALUATION - An√°lisis completo de la base de datos MongoDB
------------------------------------------------------------------
Este script conecta con la base de datos donde Unity guarda los logs (test.tfg),
los analiza y genera autom√°ticamente:
    - M√©tricas por categor√≠a (efectividad, eficiencia, satisfacci√≥n, presencia)
    - M√©tricas globales ponderadas
    - Archivos CSV/JSON exportados
    - Gr√°ficas comparativas
    - Informe PDF con los resultados
"""

import pandas as pd
import shutil
from python_analysis.log_parser import LogParser
from python_analysis.metrics import MetricsCalculator
from python_analysis.exporter import MetricsExporter
from python_visualization.visualize_groups import Visualizer
from python_visualization.pdf_reporter import PDFReport
from datetime import datetime
import os
import json
from pathlib import Path

# ============================================================
# 1Ô∏è‚É£ Conectar con MongoDB y cargar logs
# ============================================================

# Conectando con par√°metros del .env (gesti√≥n autom√°tica en LogParser)
parser = LogParser()
print(f"üîó Conectando a MongoDB ‚Üí URI: {parser.mongo_uri} | DB: {parser.db_name} | COL: {parser.collection_name}")
logs = parser.fetch_logs()

# df sin expandir ‚Üí recuperar config
df_raw = parser.parse_logs(logs, expand_context=False)

# df expandido ‚Üí m√©tricas
df = parser.parse_logs(logs, expand_context=True)
print(df.columns)

parser.close()

if df.empty:
    print("‚ö†Ô∏è  No se encontraron logs en Mongo.")
    exit()

print(f"‚úÖ {len(df)} documentos cargados desde Mongo.\n")


# ============================================================
# 2Ô∏è‚É£ Extraer config (Log vs Local override)
# ============================================================

print("‚öôÔ∏è  Leyendo configuraci√≥n del experimento...\n")

experiment_config = None

# Check override
if os.environ.get("FORCE_LOCAL_CONFIG", "false").lower() == "true":
    config_path = Path("vr_logger/experiment_config.json")
    if config_path.exists():
        print(f"‚ö†Ô∏è  FORZANDO CONFIGURACI√ìN LOCAL: {config_path}")
        with open(config_path, "r", encoding="utf-8") as f:
            experiment_config = json.load(f)
    else:
        print(f"‚ùå  No se encontr√≥ la configuraci√≥n local en {config_path}")

# Fallback/Default: Extract from logs
if experiment_config is None:
    for entry in logs:
        if entry.get("event_type") == "config":
            experiment_config = entry.get("event_context")
            break

if experiment_config is not None:
    print("‚úÖ Config cargada correctamente.\n")
else:
    print("‚ö†Ô∏è  No existe configuraci√≥n en los logs y no se forz√≥ local.\n")


# ============================================================
# 3Ô∏è‚É£ Resumen de sesiones y usuarios
# ============================================================

print("üë• Resumen de usuarios, grupos y sesiones:")

usuarios = df["user_id"].nunique()
grupos = df["group_id"].nunique()
sesiones = df["session_id"].nunique()

print(f"  ‚Ä¢ Usuarios: {usuarios}")
print(f"  ‚Ä¢ Grupos: {grupos}")
print(f"  ‚Ä¢ Sesiones: {sesiones}\n")

print("üìÑ Lista de sesiones detectadas:")
print(df[["user_id", "group_id", "session_id"]].drop_duplicates().to_string(index=False))


# ============================================================
# 4Ô∏è‚É£ Calcular m√©tricas usando MetricsCalculator
# ============================================================

print("\nüìä Calculando m√©tricas ponderadas del experimento...\n")

metrics = MetricsCalculator(df, experiment_config=experiment_config)
raw_results = metrics.compute_all()

# ------------------------------------------------------------
# ADAPTAR RESULTADO a FORMATO PARA EL PDF Y EXPORTER
# ------------------------------------------------------------
results_for_export = {}

for categoria, contenido in raw_results["categorias"].items():

    # Subestructura compatible con PDFReporter
    results_for_export[categoria] = {
        "score": contenido["score"]
    }

    for metric_name, metric_data in contenido.items():
        if isinstance(metric_data, dict):
            results_for_export[categoria][metric_name] = metric_data["raw"]

# a√±adir puntuaci√≥n global
results_for_export["global_score"] = raw_results["global_score"]

print(json.dumps(results_for_export, indent=4))


# ============================================================
# 5Ô∏è‚É£ Crear carpetas de exportaci√≥n UNIFICADAS
# ============================================================

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

base_dir = Path(__file__).parent / "pruebas"
output_dir = base_dir / f"analysis_{timestamp}"
results_dir = output_dir / "results"
figures_dir = output_dir / "figures"

# Crear estructura
os.makedirs(results_dir, exist_ok=True)
os.makedirs(figures_dir, exist_ok=True)

print(f"üìÇ Carpeta de salida creada: {output_dir}")


# ============================================================
# 6Ô∏è‚É£ Guardar config en archivo
# ============================================================

if experiment_config is not None:
    config_path = results_dir / "experiment_config_from_mongo.json"
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(experiment_config, f, indent=4)
    print(f"üìÑ Config exportada: {config_path.name}\n")


# ============================================================
# 7Ô∏è‚É£ Exportar resultados JSON + CSV
# ============================================================

print("üíæ Exportando m√©tricas...")

exporter = MetricsExporter(results_for_export, output_dir=results_dir)
exporter.to_json("results.json")
exporter.to_csv("results.csv")

grouped_df = metrics.compute_grouped_metrics()
grouped_path = results_dir / "grouped_metrics.csv"
grouped_df.to_csv(grouped_path, index=False)

# Tambi√©n exportar versi√≥n agrupada como JSON
MetricsExporter.export_multiple(
    [results_for_export],
    ["Global"],
    mode="json",
    output_dir=results_dir,
    filename="group_results"
)

print("‚úÖ Exportaci√≥n completada.\n")


# ============================================================
# 8Ô∏è‚É£ Generar figuras
# ============================================================

print("üìà Generando gr√°ficas...")

global_json = results_dir / "group_results.json"
generated_figures = 0

if global_json.exists():
    global_dir = figures_dir / "global"
    viz_global = Visualizer(str(global_json), output_dir=global_dir)
    viz_global.generate_all()
    generated_figures += len(list(global_dir.glob("*.png")))

if grouped_path.exists():
    grouped_dir = figures_dir / "agrupado"
    viz_grouped = Visualizer(str(grouped_path), output_dir=grouped_dir)
    viz_grouped.generate_all()
    generated_figures += len(list(grouped_dir.glob("*.png")))

print(f"üìä Figuras generadas: {generated_figures}\n")


# ============================================================
# 9Ô∏è‚É£ Generar informes PDF
# ============================================================

print("üìÑ Generando informe PDF...\n")

# Usar el path consolidado 'output_dir'
pdf_output_path = output_dir / "final_report.pdf"

# Priorizamos 'agrupado' para el reporte si existe, ya que es m√°s completo para gr√°ficas
report_file = grouped_path if grouped_path.exists() else global_json

if report_file.exists():
    report = PDFReport(
        results_file=str(report_file),
        figures_dir=figures_dir,  # Pasamos la ra√≠z de figuras
        output_dir=output_dir     # Pasamos la ra√≠z de output
    )
    report.generate()

print("üéâ AN√ÅLISIS COMPLETO FINALIZADO.\n")
